---
title: "Adventures in mediation analysis with weighted GLMs"
subtitle: "Race and Social Support as predictors of Intimate Partner Violence victimization in women in the Future of Families dataset"
author: Vasco Braz√£o, Priya Devendran
date: "2023"
categories: [statistics, mediation, survey, glm]
draft: true
execute: 
  warning: false
format:
  html:
    code-fold: show
---

```{r setup}
#| message: false

# load the packages we will use
library(tidyverse)
library(here)
library(mediation)
library(survey)
library(srvyr)


# directory for the post (to change once post goes live)
post_folder <- "wip_mediation-weighted-glm"
```

This blogpost documents the challenges we faced when attempting to run a mediation analysis using the `mediation` package with a binomial mediator and outcome while incorporating sampling weights into the analysis with the help of the `survey` package.

As part of a research program seeking to better understand intimate partner violence (IPV) through an intersectional lens, we wanted to use the [Future of Families & Child Wellbeing Study](https://ffcws.princeton.edu/)[^1] dataset to run a mediation analysis. The data come from a survey with a complex design, and baseline and replicate weights are provided for each participant in the "national" sample. These weights should allow us to make estimates nationally representative. (TO DO! point to the document where people can learn more about the weights <https://ffcws.princeton.edu/sites/g/files/toruqf4356/files/ff_const_wgts.pdf>) Our mediator and outcome variables could reasonably be construed as "binomial outcomes", and this was our preferred approach to fitting the necessary models. However, we encountered several difficulties XXX

[^1]: Previously called the "Fragile Families and Child Wellbeing Study"

This post has the following structure: First, we introduce the data we'll use for the demonstrations and exemplify how we would like to have run the models (TO DO: rephrase or simply change depending on final structure).

# Background: Data and desired models

For demonstrative purposes we created a synthetic dataset using the `synthpop` package. This dataset mirrors the characteristics of our data without it being possible to identify any real individuals from it.

```{r data}
# get synthetic dataset
dat <- readRDS(here::here("posts", post_folder, "data_reduced_synth.RDS")) |> 
  # create other variables we will need
  dplyr::mutate(
    informal_support_prop = informal_support/3,
    informal_support_max = 3,
    informal_support_binary = ifelse(informal_support == 3, 1, 0),
    IPV_prop = IPV/24,
    IPV_max = 25,
    IPV_binary = ifelse(IPV > 0, 1, 0)
  )
```

We have three variables that will be used for mediation, `race` ("White" or "Black"), `informal_support` (an integer from 0 to 3), and `IPV` (an integer from 0 to 24). We manually create `_prop` and `_max` variables for informal support and IPV, so that we can use the proportion as an outcome in our GLMs and use the `weights` argument to specify the number of trials. We also create `informal_support_binary`, which classifies women as having high access to informal support (takes the value 1) when they score 3 out of 3, and low access (takes the value 0) when they score less than 3, as well as `IPV_binary`, which classifies women as having experienced some form of IPV (takes the value 1) if they score more than 0 and as not having experienced IPV (takes the value 0) if they score exactly 0. These binarized variables will become useful later on.

Each person also has a baseline weight, `m1natwt`, and 33 replicate weights, `m1natwt_rep1` and so on. Behold:

```{r data.head}
head(dat) |> 
  gt::gt()
```

We'll need to run two models --- the first predicting the mediator, the second predicting the outcome --- and feed these models into `mediation::mediate()`.

## Issue 1: Correctly applying the Fragile Families weights

We fit the models using `survey::svyglm` in order to be able to take the weights into account. First, we need to tell `survey` that our data is weighted, which we do with the help of the `srvyr` package for tidyverse-like convenience. Our first attempt looked like this:

``` r
dat_weights <- dat |> 
  srvyr::as_survey_rep(
    repweights = dplyr::contains("_rep"),
    weights = m1natwt,
    combined_weights = TRUE
  )
```

However, coming across this [CrossValidated question](https://stats.stackexchange.com/questions/409463/duplicating-stata-survey-design-using-svrepdesign-from-survey-package-in-r) and confirming with the Fragile Families guide to using the weights showed us that the code above fails to tell `survey` that we want to use jackknife variance estimation. From the [guide (PDF)](https://fragilefamilies.princeton.edu/sites/fragilefamilies/files/using_the_fragile_families_weights_waves_1_6.pdf), p. 2:

> As described in the weights construction memo, the replicate weights require using jackknife estimation of standard errors.

Woops.

So, to properly apply the weights, we run this code block instead:

```{r data.weights}
dat_weights <- dat |> 
  srvyr::as_survey_rep(
    repweights = dplyr::contains("_rep"),
    weights = m1natwt,
    combined_weights = TRUE,
    type = "JKn",
    scales = 1,
    rscales = 1,
    mse = TRUE
)
```

## Running the weighted models and mediation

With the weighted dataframe in hand, we can use `survey::svyglm` to fit our GLMs predicting `informal_support` and `IPV`.

Our informal support variable is the sum of three items for which each mother could get a 1 or a 0 (indicating that she did or did not have access to that form of support). As such, it seems sensible to model it as a binomial outcome --- each mother has a certain number of "successes" out of three possible trials.

```{r model.m.ideal}
model_m_1 <- survey::svyglm(
  formula = informal_support_prop ~ race,
  weights = informal_support_max,
  design = dat_weights,
  family = "binomial"
)

summary(model_m_1)
```

We get the following warning many times:

```         
Warning: non-integer #successes in a binomial glm!
```

This is `survey`'s way of asking us to specify the family as "quasibinomial" instead of "binomial", since our outcome is a proportion (weighted by the number of trials) and not binary. However, if we do that, `mediation` will not work with our models.

Our IPV variable is the sum of twelve items for which each mother could get a score of 0, 1, or 2 (indicating how often she experienced a given form of violence from her partner). As such, it also seems sensible to model it as a binomial outcome --- each mother has a certain number of "successes" out of 24 possible "trials".[^2]

[^2]: Another option, which we won't go into, would be to take the responses to the items themselves and use a multi-level ordinal model with item as the random grouping factor.

```{r model.y.ideal}
model_y_1 <- survey::svyglm(
  formula = IPV_prop ~ race + informal_support_prop,
  weights = IPV_max,
  design = dat_weights,
  family = "binomial"
)

summary(model_y_1)
```

(Here again we suppressed the warning that would have otherwise popped up.)

Finally, our mediation:

```{r mediation.ideal}
med_1 <- mediation::mediate(
  model.m = model_m_1,
  model.y = model_y_1,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_prop"
)

summary(med_1)
```

A small but statistically significant mediation effect! The warning about weights not being taken as total number of trials makes us nervous, but then again, we did give the models sampling weights, so maybe it's ok?

## Issue 2: Mediation with "multiple-trial binomial mediator" runs for weighted but not for unweighted models?

We knew that we would eventually perform a sensitivity analysis where all models would be run without using the sampling weights. Running the previous steps with the `glm` command resulted in an issue:

```{r unweighted.mediation.ideal.fail}
#| error: true

model_m_2 <- glm(
  formula = informal_support_prop ~ race,
  weights = informal_support_max,
  data = dat,
  family = "binomial"
)

model_y_2 <- glm(
  formula = IPV_prop ~ race + informal_support_prop,
  weights = IPV_max,
  data = dat,
  family = "binomial"
)

med_2 <- mediation::mediate(
  model.m = model_m_2,
  model.y = model_y_2,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_prop"
)
```

It seems like `mediation::mediate` is taking the weights we pass to the GLM function (which correspond to total number of trials, not to sampling weights) as sampling weights, and complaining when it notices that these weights are not the same for the mediator and outcome models. Vasco perhaps clumsily posted this as an [issue on the mediation package Github](https://github.com/kosukeimai/mediation/issues/59), but at least for now there has been no answer. We can work around this by using an alternative way of specifying the same GLM model --- instead of using a proportion as an outcome and passing the number of trials through the `weights` argument, we can instead use a vector of "successes" and "failures" (which corresponds to the total number of trials minus the number of successes) as the outcome:

```{r unweighted.mediation.ideal.workaround}
model_m_2.1 <- glm(
  formula = cbind(informal_support, informal_support_max - informal_support) ~ race,
  data = dat,
  family = "binomial"
)

model_y_2.1 <- glm(
  formula = cbind(IPV, IPV_max - IPV) ~ race + informal_support_prop,
  data = dat,
  family = "binomial"
)

med_2.1 <- mediation::mediate(
  model.m = model_m_2.1,
  model.y = model_y_2.1,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_prop"
)

summary(med_2.1)
```

Success! But at the cost of suspicion. The [documentation for the `mediate` function](https://www.rdocumentation.org/packages/mediation/versions/4.5.0/topics/mediate) warns us that (emphasis added):

> As of version 4.0, the mediator model can be of either 'lm', 'glm' (or \`bayesglm'), 'polr' (or \`bayespolr'), 'gam', 'rq', \`survreg', or \`merMod' class, corresponding respectively to the linear regression models, generalized linear models, ordered response models, generalized additive models, quantile regression models, parametric duration models, or multilevel models.. For binary response models, the 'mediator' must be a numeric variable with values 0 or 1 as opposed to a factor. Quasi-likelihood-based inferences are not allowed for the mediator model because the functional form must be exactly specified for the estimation algorithm to work. **The 'binomial' family can only be used for binary response mediators and cannot be used for multiple-trial responses**. This is due to conflicts between how the latter type of models are implemented in [**`glm`**](https://www.rdocumentation.org/link/glm?package=mediation&version=4.5.0) and how 'mediate' is currently written.

Thus, until the package author clarifies whether this implementation results in correct estimates, we are cautious about trusting them.

### Sanity check: comparing results with linear probability models

As a sanity check, to become a little more confident that `mediate` is working as intended even though it's not supposed to work well with a multiple-trial binomial mediator, we compare the results of our model that did run (`med_2.1`) with a mediation run on linear probability models (basically, using `lm()` instead of `glm()` even though the outcomes are proportions.

```{r unweighted.mediation.ideal.sanity.check}
model_m_2.2 <- lm(
  formula = informal_support_prop ~ race,
  data = dat
)

model_y_2.2 <- lm(
  formula = IPV_prop ~ race + informal_support_prop,
  data = dat
)

med_2.2 <- mediation::mediate(
  model.m = model_m_2.2,
  model.y = model_y_2.2,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_prop"
)

summary(med_2.2)
```

The results seem fairly similar, but this provides limited comfort.

### Bonus finding: you can specify a mediator that is not technically the variable that your mediator model predicts

Note that in the models used for `med_2.1` there is a potential discrepancy. The mediator model is formulated as `formula = cbind(informal_support, informal_support_max - informal_support) ~ race`, while the outcome model is formulated as `formula = cbind(IPV, IPV_max - IPV) ~ race + informal_support_prop`. So the outcome model is using `informal_support_prop` (our intended mediator) as a predictor of IPV, but the mediator model uses the variables `informal_support` and `informal_support_max` to internally generate the proportion of successes. In the call to `mediation::mediate` we can then specify `mediator = "informal_support_prop"`, and all seems to work as intended. What if we used `informal_support` as predictor in the outcome model instead? We can then specify `mediator = "informal_support"` and end up with something like this:

```{r unweighted.mediation.ideal.bonus}
model_m_2.3 <- glm(
  formula = cbind(informal_support, informal_support_max - informal_support) ~ race,
  data = dat,
  family = "binomial"
)

model_y_2.3 <- glm(
  formula = cbind(IPV, IPV_max - IPV) ~ race + informal_support,
  data = dat,
  family = "binomial"
)

med_2.3 <- mediation::mediate(
  model.m = model_m_2.3,
  model.y = model_y_2.3,
  sims = 1000,
  treat = "race",
  mediator = "informal_support"
)

summary(med_2.3)
```

Looking at the last three rows (Average Causal Mediated Effect (average), Average Direct Effect (average), and Proportion Mediated (average)), results seem different than the ones estimated in `med_2.1` (which used `informal_support_prop` as mediator) and `med.2.2` (which used linear proability models). But looking closer, you'll notice that the estimates related to the mediator, namely of the Average Causal Mediated Effect and the Proportion Mediated just seem to be divided by three!

My assumption about how that came to be: When we use `informal_support_prop`, which can only take values on the $(0, 1)$ interval, the ACME estimates correspond to the change in probability of IPV associated with going from 0 to 1 on the mediator and thus span the full range of the mediator. When we use `informal_support`, which takes values in the set $\{0, 1, 2, 3\}$, the estimates also correspond to the increase in probability of IPV associated with an increase of 1 on the mediator (e.g., from 0 to 1), but this is only $\frac{1}{3}$ of the total possible way. Thus, applying this effect three times would be equivalent to moving from 0 to 3 on the mediator scale, the same as moving from 0 to 1 when the mediator is a proportion.[^3]

[^3]: Of course, the effects mentioned here are not really the effects of moving from X to Y on the mediator, but the mediated effect that changing from Race = "White" to Race = "Black" has on the probability of IPV *through its effect on the mediator*.

## Issue 3: Using a binary mediator and a binomial outcome --- works with cbind(successes, failures) but not with proportion as outcome and weights argument specified

Next, we attempted to run everything with the same binomial outcome and a binary mediator.

```{r unweighted.binary.mediator.fail}
#| error: true

model_m_3 <- glm(
  formula = informal_support_binary ~ race,
  data = dat,
  family = "binomial"
)

model_y_3 <- glm(
  formula = IPV_prop ~ race + informal_support_binary,
  weights = IPV_max,
  data = dat,
  family = "binomial"
)

med_3 <- mediation::mediate(
  model.m = model_m_3,
  model.y = model_y_3,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_binary"
)
```

Once again we find that `mediate` complains about different weights on mediator and outcome models, even though, according to the documentation, it works with a binary mediator and a binomial outcome. We then try using the vector of successes and failures specification for the outcome model:

```{r unweighted.binary.mediator.success}
model_y_3.1 <- glm(
  formula = cbind(IPV, IPV_max - IPV) ~ race + informal_support_binary,
  data = dat,
  family = "binomial"
)

med_3.1 <- mediation::mediate(
  model.m = model_m_3,
  model.y = model_y_3.1,
  sims = 1000,
  treat = "race",
  mediator = "informal_support_binary"
)

summary(med_3.1)
```

This approach runs, but we are still left wondering whether we can trust the estimates.
